{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from surprise import SVD, NMF, SlopeOne, NormalPredictor, CoClustering, BaselineOnly, KNNBasic, KNNWithMeans, Dataset, Reader, accuracy\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = open(\"./MovieLens/20m/users_20m_sample_section.csv\").read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./MovieLens/20m/train_ratings_20m_sample_section.csv\")\n",
    "test = pd.read_csv(\"./MovieLens/20m/test_ratings_20m_sample_section.csv\")\n",
    "train = train.rename(index=str, columns={\"userId\": \"userID\", \"movieId\": \"itemID\"})\n",
    "test = test.rename(index=str, columns={\"userId\": \"userID\", \"movieId\": \"itemID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVD algorithm\n",
      "Training NMF algorithm\n",
      "Training CoClustering algorithm\n",
      "Training SlopeOne algorithm\n",
      "Training NormalPredictor algorithm\n",
      "Training BaselineOnly algorithm\n",
      "Estimating biases using sgd...\n",
      "Training KNNBasic_UserBased algorithm\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training KNNWithMeans_UserBased algorithm\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training KNNBasic_ItemBased algorithm\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training KNNWithMeans_ItemBased algorithm\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Running SVD algorithm...\n",
      "SVD took: 1.2320363521575928s\n",
      "Running NMF algorithm...\n",
      "NMF took: 1.0949034690856934s\n",
      "Running CoClustering algorithm...\n",
      "CoClustering took: 0.9882099628448486s\n",
      "Running SlopeOne algorithm...\n",
      "SlopeOne took: 10.139931440353394s\n",
      "Running NormalPredictor algorithm...\n",
      "NormalPredictor took: 0.9720468521118164s\n",
      "Running BaselineOnly algorithm...\n",
      "BaselineOnly took: 1.8836166858673096s\n",
      "Running KNNBasic_UserBased algorithm...\n",
      "KNNBasic_UserBased took: 3.7278645038604736s\n",
      "Running KNNWithMeans_UserBased algorithm...\n",
      "KNNWithMeans_UserBased took: 3.777837038040161s\n",
      "Running KNNBasic_ItemBased algorithm...\n",
      "KNNBasic_ItemBased took: 15.005200386047363s\n",
      "Running KNNWithMeans_ItemBased algorithm...\n",
      "KNNWithMeans_ItemBased took: 14.266334533691406s\n"
     ]
    }
   ],
   "source": [
    "reader = Reader()\n",
    "\n",
    "db = Dataset.load_from_df(train[['userID', 'itemID', 'rating']], reader)\n",
    "trainset = db.build_full_trainset()\n",
    "\n",
    "algs = {\n",
    "    'SVD': SVD(random_state=42),\n",
    "    'NMF': NMF(random_state=42),\n",
    "    'CoClustering': CoClustering(random_state=42),\n",
    "    'SlopeOne': SlopeOne(),\n",
    "    'NormalPredictor': NormalPredictor(),\n",
    "    'BaselineOnly': BaselineOnly(bsl_options={'method':'sgd'}),\n",
    "    'KNNBasic_UserBased': KNNBasic(sim_options={'user_based': True, 'name': 'cosine'}),\n",
    "    'KNNWithMeans_UserBased': KNNWithMeans(sim_options={'user_based': True, 'name': 'cosine'}),\n",
    "    'KNNBasic_ItemBased': KNNBasic(sim_options={'user_based': False, 'name': 'cosine'}),\n",
    "    'KNNWithMeans_ItemBased': KNNWithMeans(sim_options={'user_based': False, 'name': 'cosine'})\n",
    "}\n",
    "\n",
    "for name in list(algs.keys()):\n",
    "    print('Training {} algorithm'.format(name))\n",
    "    algs[name] = algs[name].fit(trainset)\n",
    "\n",
    "results = {}\n",
    "for name, alg in algs.items():\n",
    "    print('Running {} algorithm...'.format(name))\n",
    "    results[name] = {}\n",
    "    initial = time.time()\n",
    "    for user in users:\n",
    "        data_te = test.loc[test['userID'] == int(user)]\n",
    "        db = Dataset.load_from_df(data_te[['userID', 'itemID', 'rating']], reader)\n",
    "        testset = db.construct_testset(db.raw_ratings)\n",
    "        predictions = alg.test(testset)\n",
    "        results[name][user] = {'RMSE': accuracy.rmse(predictions, verbose=False)}\n",
    "    final = time.time()\n",
    "    print('{} took: {}s'.format(name, final-initial))\n",
    "#     print('Results for {} algorithm:'.format(name))\n",
    "#     print(results[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.json', 'w') as result_file:\n",
    "    json.dump(results, result_file, indent=4, sort_keys=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
