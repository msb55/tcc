{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, csv, itertools\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = open(\"C:\\\\Users\\\\barre\\\\Documents\\\\UFPE 2015\\\\TCC\\\\MovieLens\\\\basic\\\\users_basic_sample.csv\").read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = './Results/Surprise/mae/'\n",
    "\n",
    "results_files = ['BaselineOnly(SGD).txt',\n",
    "'CoClustering.txt',\n",
    "'KNNBasic(Itembased).txt',\n",
    "'KNNBasic(Userbased).txt',\n",
    "'KNNWithMeans(Itembased).txt',\n",
    "'KNNWithMeans(Userbased).txt',\n",
    "'NMF.txt',\n",
    "'NormalPredictor.txt',\n",
    "'SlopeOne.txt',\n",
    "'SVD.txt']\n",
    "\n",
    "mae_results = 'mae_results.json'\n",
    "\n",
    "answer_matrix = 'answer_matrix_mae_.csv'\n",
    "time_matrix = 'time_matrix.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(root_dir):\n",
    "    results = []\n",
    "    for file in results_files:\n",
    "        with open(os.path.join(root_dir, file)) as result:\n",
    "            content = result.read().split('\\n')[3:]\n",
    "            results.append(json.loads(''.join(content)))\n",
    "        result.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(root_dir):\n",
    "    results = read_results(root_dir)\n",
    "    time = []\n",
    "    for user in users:\n",
    "        time.append(list(map(lambda x: x[user]['time'], results)))\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(filename, headers, rows):\n",
    "    with open(os.path.join(parent_dir, filename), 'w', newline='') as file:\n",
    "        file_writer = csv.writer(file)\n",
    "        file_writer.writerow(headers)\n",
    "        for row in rows:\n",
    "            file_writer.writerow(row)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_scale(root_dir, metric='RMSE', results=None):\n",
    "    if root_dir:\n",
    "        results = read_results(root_dir)\n",
    "    rmse = []\n",
    "    for user in users:\n",
    "        rmse.append(list(map(lambda x: x[user][metric], results)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_scale(root_dir, all_=False):\n",
    "    results = read_results(root_dir)\n",
    "    results_list = list(map(lambda x: list(map(lambda y: y[1]['RMSE'], x.items())), results))\n",
    "    if all_:\n",
    "        results_normalized = list(itertools.chain.from_iterable(results_list))\n",
    "        results_normalized = 1-normalize([results_normalized])\n",
    "        results_normalized = list(map(list, list(zip(*[iter(results_normalized[0])] * 200))))\n",
    "    else:\n",
    "        results_normalized = 1-normalize(results_list)\n",
    "    return np.transpose(results_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(root_dir, all_=True):\n",
    "    results = read_results(root_dir)\n",
    "    results_list = list(map(lambda x: list(map(lambda y: y[1]['RMSE'], x.items())), results))\n",
    "    rmse = []\n",
    "    if all_:\n",
    "        big_list = list(itertools.chain.from_iterable(results_list))\n",
    "        r_max = max(big_list)\n",
    "        r_min = min(big_list)\n",
    "        rmse = list(map(lambda x: (r_max - x)/(r_max - r_min), big_list))\n",
    "    else:\n",
    "        for result in results_list:\n",
    "            r_max = max(result)\n",
    "            r_min = min(result)\n",
    "            rmse.append([(r_max - x)/(r_max - r_min) for x in result])\n",
    "        rmse = list(itertools.chain.from_iterable(rmse))\n",
    "    rmse = list(map(list, list(zip(*[iter(rmse)] * 200))))\n",
    "    rmse = np.transpose(rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(root_dir=None, metric='RMSE', results=None):\n",
    "    if root_dir:\n",
    "        results = read_results(root_dir)\n",
    "        \n",
    "    if results:        \n",
    "        results_list = list(map(lambda x: list(map(lambda y: y[1][metric], x.items())), results))\n",
    "        results_normalized = list(itertools.chain.from_iterable(results_list))\n",
    "        results_normalized = list(map(lambda x: 1/(1+x), results_normalized))\n",
    "        results_normalized = list(map(list, list(zip(*[iter(results_normalized)] * 200))))        \n",
    "        return np.transpose(results_normalized)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale2(results, metric='mae'):\n",
    "    normal = list(map(lambda x: x[1][metric], results['NormalPredictor'].items()))\n",
    "    results_list = []\n",
    "    for alg, value in results.items():\n",
    "        results_list_temp = list(map(lambda x: x[1][metric], value.items()))\n",
    "        results_list.append(list(map(lambda x: 1/(1+(x[0]/x[1])), list(zip(results_list_temp, normal)) )))\n",
    "        \n",
    "    results_normalized = list(itertools.chain.from_iterable(results_list))\n",
    "    results_normalized = list(map(list, list(zip(*[iter(results_normalized)] * 200))))        \n",
    "    return np.transpose(results_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = [file.replace('.txt', '') for file in results_files]\n",
    "# rmse = standard_scale(parent_dir)\n",
    "# write_file(answer_matrix, headers, rmse)\n",
    "# write_file(time_matrix, headers, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_results_file = open(parent_dir+mae_results)\n",
    "results = json.load(mae_results_file)\n",
    "headers = list(results.keys())\n",
    "mae = standard_scale(metric='mae', results=[value for _, value in results.items()])\n",
    "# mae = without_scale(root_dir=None, metric='mae', results=[value for _, value in results.items()])\n",
    "write_file(answer_matrix, headers, mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
